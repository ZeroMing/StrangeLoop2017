    "It Me: Under the Hood of Web Authentication
    Yan Zhu and Garrett Robinson
    
    (technical difficulties - first few minutes missed by captioner)
     >> Yeah, I would have guessed password, but it turns out the password limit requirement was 6, so it was
    >> Some people were like, this is the same password I use on Gmail, you know, it's the same password I use on all my accounts. So basically if you got this, it's easy to pivot that into hacking into people's emails and stuff. You're given these hints, you he a given these opaque strings, you have to solve for what these strings are based on a hint, so this is the greatest crossword puzzle in the history of the world, pretty much.
    [laughter]
    
    And for users, it was a garbage fire, you know, a lot of their passwords could have been trivially exposed and if you could somehow get the single encryption key to -- that Adobe used then you could decrypt all 150 million passwords, but let's assume your users logged in. What could go wrong?
    >> Yeah, so let's assume that you are storing passwords securely and your users logged in as you guys are probably aware, HTTP is a stateless protocol so we need some way to remember that we logged that person in, who they are, what their deal is, etc. So this is a quick overview, it's probably a review for a lot of you guys, so typically as a developer, you have some kind of a session abstraction provided to you by your web framework. And this is usually like a key value store, like a dictionary and you put arbitrary data into it and the framework handles the rest of what I'm about to talk about. So there's two broad common kinds of web sessions. There are these stateless sessions, in which all the session data is sent to the client, so in Python land, which is what I'm familiar with, the flask micro-framework does this by default and if you guys are more into JavaScript and you're using JWTs which are apparently all the rage that's basically the exact same thing, but with some more structure and some more vulnerabilities.
    
    [laughter]
    
    There's also server-side sessions which are very, very common, where you store all the ... Data on the server. For example, this is what Danco does by default. Once, so once you have this session data, you include it in a response, and you want it to be persistent on the client. The classic way to do this is cookies. That's what they were designed to do, and cookies aren't the greatest. You might be familiar with their bizarre behavior that intersects with the same origin policy in a web browser, but also doesn't and has a will the of weird caveats and exceptions, but over time we've kind of evolved features to add to cookies that makes them pretty reasonable for managing sessions so for example, there's this HTTP-only flag and what that means is JavaScript is not able to modify a cookie via the document.cookie accesser in JavaScript. And that's actually good so your cookies can't be stolen and used elsewhere. There's also a secure flag. Which is also a really good thing.
    More recently, people are kind of fed up with cookies and want to use something that's more flexible and more ergonomic for developers so you're using your local storage in your browser and that has benefits but it also is kind of a back-pedal in some ways, you're vulnerable XSS, but there are some tradeoffs. They both have their pluses and minuses. There's no real clear winner here. Great, so once you know how you're going to store it is, you send that to the client and then the client persists it and will send it back to you in subsequent requests and that's how you maintain this state over time. So one problem with the sessions is that you might store date in there that the user has an interest in modifying. Maybe, you know Alice has an account on your site, she has some credits and she wants to do stuff but she thinks she deserves more of a balance to start with, right? So if you could just arbitrarily modify the session data, which you could in like a totally naive documentation, then all kinds of stuff could happen. There's all kinds of ways to avoid this but the real pattern is to use message authentication codes, or MACs, not laptops, but message authentication codes. You feed them both into the MAC algorithm and it creates this thing called a MAC tag. And the MAC algorithm is derived so it's difficult to generate a MAC tag if you don't know the key K. So you transmit your message through the tag through the untrusted environment which is the dark void between these pastel squares and when the receiver gets the message with the MAC tag they recompute the tag with the receiver that they know, if they, integrity is good to go, you're safe, other ways, shenanigans are under foot. This is good in the web says because the sender and the entity are the same, right in it sends itself to itself through a round trip to the client which is maybe a little bit confusing to people. So one common gotcha, this affects Flask, which is the example that I'm given here is that sessions are signed but they're not encrypted and that isn't always a problem. It's just a random session ID. It doesn't matter if someone can read it, but in some cases you might store information in the session that your users should not be able to read. This is kind of a toy example where you have a guess the number web app, because we need those. And you know, basically what you do is you generate a number between 1 and 10, you store it in the session, that's the correct answer, you return it to the user, and then when they submit their guess, you just compare what was in the form they submitted, to what was in the session. But because the session was persistent on their machine and it's not encrypted, they could just look at it and get the right answer every single time. This actually is a problem that you will see in various applications. I've audited several applications that do more complicated things but with the same basic kind of misconception about how the underlying abstraction works and it can be a pretty serious problem.
    >> So another gotcha appears when you start comparing these MAC tags. That is, when you're trying to verify that the MAC is the expected value on the server. The obvious way is to use equal-equal on two strings as a string comparison, but there's kind of a subtle problem here, which is that this = = function terminates as soon as there's a prefixed mismatch between the two strings. For instance, if MAC starts with K and correct MAC starts with B. Then the function match says oh, this doesn't match so we're going to stop here but if they have a longer prefix in common, then the function will run for a longer time. So the time it takes to run this varies depending on how similar A and B are. So I'll share these slides later. I wrote a little demo of this in Node. So the reason this can become a problem is when an attacker can measure the timing, they shouldn't learn any information about what the secret input is. And this is a pretty common problem that people have in their code. I actually saw it in an early version of Let's Encrypt, which a lot of people use. So I did a little demo which I'm not going to run, but it basically does this = = password function, so the actual password is foo, and we compare aaa, aba, etc. and we measure the time it takes for that comparison to finish and indeed, even on this toy, very simple piece of code you can see there's some timing variation. When there's no prefix mismatch, when there's no prefix match, it finishes faster in about 91 nanosecond and all the way on your right where there's a full match on the string foo, it's about 115 nanoseconds, so there are clear timing variations and you can see this even in a language like JavaScript.
    And you might ask, so is this kind of timing difference of you know, several nanoseconds measurable over the network? There's a 2007 study that found that you can get about 15 to 100 microsecond accuracy across the internet and as good as 100 nanoseconds over a local network so that's almost a same order of magnitude as I just showed. So there's good evidence these attacks are practical in some situations. Just to go over this, how can attacker abuse this timing difference if they're trying to brute-force a MAC. Let's say the MAC is hex encoded so first they can try 0000, then they can try 1 as the first character and then a 2 all the way up to F. So they measured a MAC verification time for each of these strings and they say, well, the one that took the longest probably had a prefix match so that's probably the right first character then they go on to repeat this for the second character and over and over again and they've brute-forced the entire secret. So one way to solve this problem in your code is to do a constant time comparison. This is a common way I've seen it done in Python and Node and other languages. Basically you loop through the strings that you're comparing, that's the four-loop with the charcodeat. You execute if they match they're 0, if they don't, they're a 1. So basically only if all of them match is the entire result 0. So that's a pretty easy way to do that. So in Node someone pointed out in 2015 or 2016, that they weren't doing timing safe equality checks so Node actually recently added this API crypto timing safe equal so you can just plot it into your code and I did that in my code earlier and you can see my code is slower by about an order of magnitude but things are not running in ha way that reveals my secret. Or at least not obviously.
    So constant time comparison, the security researcher Brad Hill has this quote where he says it's good for native code, but in high-level languages, there are some problems. So he found that source code which looks like it's constant time, doesn't always run that way, because the compiler, the jit and run-time optimizers don't recognize timing as a program semantic, so in other words, there's no guarantee that this function will be constant. So how do you solve that? Well, a simple way is to blind the timing channel, so instead of comparing these tougher strings directly, apply a pseudorandom function to the two strings and then compare the outputs, so by definition the outputs are uncorrelated to the inputs, they're just random functions of it, and so now when someone tries to measure a timing, they're measuring a timing of the Rand string, not the timing of the inputs. So common pseudorandom function is h MAC and you can get that from the Node crypto easily. So here I just H MACed both of my inputs and that runs even slower.
    [laughter]
    
    >> I like the -- I like the use of an HMAC to verify a HMAC. It's kind of like the yo, dog of functions. OK, so let's say that you've got these first two critical components down, you're storing passwords securely and you're managing sessions securely. No timing attacks, that's pretty good. There's a lot more that you could do wrong, but this is like a survey of very common things that people do wrong. So unfortunately even if you as a developer do everything right here, you audit your libraries, you make sure your own code is secure, your users might still end up being hacked, mostly because users as we saw earlier are really bad at choosing passwords, they choose weak passwords and they reuse them across multiple sites all the time. A lot of you guys are technically Varkey, so you probably use a password manager. Amazing, you guys are awesome!  But so the actual percentage of people who use password managers out of the entire population is very, very small. I think you have a number on it later, it's quite small. So password managers themselves are not a great solution for the majority of people, at least not yet, and they also create their own tradeoffs for security. I mean what if your password manager is could compromised? So what else can we do to protect consumers even though we know they're humans who make mistakes.
    The idea is to create this concept of an authentication factor. So there's knowledge factors, something you know, like a password, possession factors, that's like something you have like a key or a phone, and something you are, like your fingerprint for touch ID or your entire face, I guess is the new thing.
    [laughter]
    
    But on the web, we don't really see these inheritance, these like something you are factors yet. Mostly we see a combination it have password and there's a huge variety of designs and tradeoffs and constraints. So let's take a look at some common examples. Can I get a show of hands of people who did this of send a code to your phone when you log into web pages. Not as many but a lot of people. Cool. Yeah, so this is a really common technique for 2-factor authentication. In this case the possession factor is your cell phone. When you log into an account after they check your password, they'll generate a short code, send you a text and you're supposed to type it in and that proves that you have your phone. This is actually a really common technique mostly because it's really low friction. As a user, you don't need to get a new device or install any apps. Like you just receive a text and there's a lesser appreciated reason in why it is really nice in that it helps you manage the life cycle of this 2-factor device. A lot of people lose their phones and they don't have backups, but you can still receive texts on your phone number which doesn't tend to change that often. So there are some benefits to this, about you in general it's really bad. You guys might remember in August of last year, or June of last year, the activist Derae McKesson was hooked. And asked to port his number to a card that they controlled, at which time they received all his text, including his one-time passwords. More recently we've been seeing these attacks that exploit the SS7 routing protocol and handles SMS around the world. So thieves stole money and just last week a security firm demonstrated a proof of concept where you can drain somebody's Bitcoin with the same type of attack.
    So maybe you have like a really important online account, like people read it a lot, don't know why, but they do, and you want to make sure that people can't take it over, log into it and do weird stuff. So is there something better than these SMS one-time passwords? Well, the next step up is kind of these HMAC or time-based one-time passwords. You've probably seen these little hardware tokens or maybe you have an app on your phone like Authy or Google: When you're scanning that QR code at the beginning that's communicating a random secret key to your device and it combines the secret key and a moving factor so in the case of HTTP, that's a simple counter, that's 1, 2, 3, etc. and you take the current time and modulo it and get a different counter. They're almost the same algorithm. But this is really nice, there's no SMS. There's no transport layer, the code is on your device and you type it? And if you have the option to switch to this, it might not be a bad idea. Quick aside: It's great if you have the option to switch to this so you can have a more secure solution for logging in than SMS one-time passwords, but it's really important that the software provider honors that. So for Twitter, for example, you'd think after the Deray hack they would offer some more secure options than SMS options. And if you go to their site it sounds really promising and I logged in and again and I logged out again and this is what I got. This is a page that said, hey, we texted you a one-time password and I was like, what? So they do this for usability, right? Like people complain that the SMSOTPs don't work if when you have no cellular service like if you're on an airplane. But this just fails to achieve that. So if anyone here works at Twitter? Maybe take a look at this, and -- in general, takeaway for everybody is it's really good to think about what the tradeoffs are with these systems and they are complicated but when you can, it's really good to give your users the option to protect themselves. SMA-OTPs are the end of the world. They do give people some options but it's good to step it up.
    In both these cases you're still talking about a one-time password type of a scheme and these are always vulnerable to other attacks, the most common one is phishing. This is a phishing page, it looks like a Google "change your password" page. But you can see it's logins.logins.verify.com which I'm pretty sure is not a Google registered domain name. So if you were taken to this site, you were tricked, it says put in your current password and after you hit change your password they're like hold on I'm going to need a two-factor phone. The attackers receive it and then turn man in the middle the login in real time they get into your account and that's the end of your story. This is an attack by the Iranian government against activists in 2015. So the good news is there's been some really promising developments in this regard in the past couple of years. Anybody here heard of U2F for security keys and use them? More heard, less use. Maybe I can convince you. So this is a really cool standard. It was developed initially internally at Google and then they created this industry group called FIDO and it's being reworked the W3C in this spec. So meant to be a comprehensive two factor design that tries to solve a lot of these problems at once. Here's how it works.
    So there's kind of like three components of U2F. So already it's a little more complex than it was before, but on the right you have the relying party. In UTF speak that's the website you're logging into, so Google.com. You have the client's browser, and some kind of thing that stores the secret data on your behalf. That could be a dedicated token, it could be your phone. There's a lot of options. So at a very high level it's a challenge and response protocol.S the relying party says I want to make sure you're really you and you prove that you have access to this physical thing so I'll send you this challenge. The developer will send a and challenge to the device and return the signature of the challenge back to the party who has a copy of the public key. If you've ever used SSH with public keys it's very similar at a high level to that protocol. But this actually adds a lot more onto that very simple idea, so the next step is that the relying party that generates a challenge, and then it sends it to the client and then the client kind of extends that with some additional information. The first and the most important is that it adds the origin of the request, so in that phishing example, that would be login verify.com or whatever and so when the user created this public-private key associated with their real Google account, that was Google.com and it maps these private keys using the origin, so in this case, that earlier attack is totally foiled. There's just no way that that device will return a valid signature for the wrong domain. And they keep layering these additional ideas. There's too many to talk about here but one that's kind of cool is there's an optional thing that allows you to create a unique identifier between yourself and a server and you can actually kind of include those in these assertions and challenges as well. And that means that even if you have an attacker who's able to obtain a valid TLS certificate, they still won't be able to man in the middle your authentication process because it won't be able to spoof the channel ID.
    So while it's a fairly complex protocol, the user experience is still reasonable. You have to do a user action as they're called on the device, that's tapping a button or responding to a prompt on your phone, and then you're good to go.
    Cool. So this has been kind of in the works for a while and as we heard from the audience earlier, people have been hearing about it but not enough people have been using it and the reason why is there's a big tradeoff with U2F, which is that in order for it to work you need buy-in for two separate constituencies. You need clients, like web browsers to support the protocol, and you need the relying parties, the websites, to add support for U2F as an option for authentication. The cool thing is that today U2F devices are cheap, they're usually about $20 or less. And they're available at a growing number of manufacturers. Brad Hill, is collecting reviews of these devices in a GitHub repository. So if you're interested in getting one, a lot of smart security folks are really tearing these things apart and trying to figure out which ones are the best. The main problems are iOS support. For Android, you can buy a key that has support. So you can tap that on your phone if you have Android but Apple doesn't make it available to third party applications so that's not possible right now. In addition, there are some kind of experimental new ideas like GitHub has this recent thing called soft U2F it's a software token. So when U2F was designed originally people were into hardware, they were like keep the key in the hardware, but for a lot of people that isn't the concern, that isn't the kind of adversary they're worried about. They can still realize a lot of the benefits by U2F by running it in software and so soft U2F stores your keys in the MAC 2F keychain. It's a new project. It's a work in progress. So check that out.
    As for the clients, Chrome has support for a long time. Awesome news, just last week, Firefox Nightly landed support for U2F which is great and that will make it to the stable release in about 6 weeks and when it does, I think about 80% of web browsers worldwide will have support for U2F, which is pretty great. Finally websites, there's been kind of a parade of big websites rolling out U2F as the good word spreads and you can see a full list at this dongle.auth.info, a really clever name for a site. I would say if you're working on your own authentication, and you're protecting user sensitive data, maybe you would consider adding it an an option to your own site.
    >> So finally I wanted to talk about some password list login systems, because while these things Garrett talks about are really nice, they're kind of all addressing very fundamental weaknesses in password systems.
    >> It's no surprise that passwords are kind of unusable for the average people. There's all these problems, like people forget them or lose them, they pick weak passwords, they pick weak passwords and then they reuse them on 20 different accounts and password databases get hacked a lot. Let's just say that. Unlike this room which is not a representative sample,
    [laughter]
    
    Only about 5% of Americans use a password manager as their primary way to save passwords. Most people in this survey said they just memorize them or wrote them down or something or just use the same one on all sites.
    So we can make some observations, which is that Garrett talks about all these ways you could do 2-factor such as SMS and a related method is the verify push notification that you may have seen on Google or Facebook where going says you're trying to log into your computer we're going to send you the verify to your Gmail app on your phone and you tap that to log in. And both of these are much more convenient for most people than remembering and typing in passwords. And also, given multiple ways of authenticating, users don't usually pick two factors, they only set up one of them. So some people have been thinking why don't we just use what we've traditionally used as the second factor as the primary way for people to log in. And what would that look like?
    >> So as of 2015, Yahoo email tried this each time you sign in you will receive a push notification on your mobile phone for you to approve. And once you do that, you'll be logged in completely. This kind of makes sense for Yahoo because they've had a number of password breaches in the past and their users don't always pick the best password and they don't set up 2 factor, so in this case, you could strongly argue that the second factor, push notification is stronger than the first factor, which is passwords. So looks like this: You put in your user name on Yahoo mail. It sends you an account key and it just says are you trying to sign in? Tap yes and you're done. So it's just proof of authentication by possession instead of passwords. So there's a service called auth0 that does this, but for mobile they only offer -- well, they offer S MS and email, but they don't offer push notifications, so if you're using something like this, just keep in SMS is easy to hack, as Garrett said earlier. There's another thing that's kind of weird about password login systems that you may have noticed, which is that they're about only as secure as your email account. Because if someone doesn't have your password, but they do have access to your email, they could go to Slack.com and say I forgot my password, and they can log in together and see all your Strange Loop messages. So Slack actually kind of took this idea and turned it into a first-class login option which you've probably seen. It's called magic links, so this is from the Slack desktop app and it says, it has the sign-in box and then it has two options, forgot password or is your password too long to type, mail me a link. Amazingly these are pretty much the same. You click that, the token gets used and you log in by proving you control your email account and that's a pretty nice user flow, especially if passwords are hard to type on your phone.
    But so a point here to make is is email secure in transit? So for websites, people are all -- well, most people are familiar with HTTPS, right? You see the lock icon. That means it's safe to enter your password on your banking site or whatever. But email is a bit different. It uses a protocol called start TRS which under the hood is similar to SMS except it's opportunistic. So the. First server is like, what's up? The second server says, I support encryption, the first server says, well, I also support encryption, so let's have an encrypted conversation so then they start encrypting and everything is great. The problem is, up until the encryption happens, all of these messages are in plain text, so an attacker can do this. Server says what's up? Server two says, "I support encryption," but then a man in the middle pretending to be a secure site will say I don't support encryption. But people really expect their email to be delivered, right? Like there's this expectation of reliability when you send a Gmail to your boss that it will get there. So for this reason, most email providers have made the tradeoff that they will send the email anyway, even if encryption is not negotiated. So in most cases, server two will say, OK, yeah, here's my password anyway. And that's not great. But the good news is startTLS support has gone up. Initially some services didn't support this type of encryption and around 2014, 2015, that started rising pretty dramatically. But it's not perfect yesterday. So faux for instance yesterday yesterday I booked a flight and got this little red icon in Gmail, which means that was not securely encrypted. So now everyone can have my passport information.
    >> We'll take questions. I think. After. Yeah, thanks.   
    [applause]
